{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crazy-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heard-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from scipy.stats import norm\n",
    "from sklearn.cluster import OPTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-hartford",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-above",
   "metadata": {},
   "source": [
    "the data generating process is:\n",
    "\n",
    "$y=ax$\n",
    "\n",
    "where **a** stands for pose, **y** for camera coordinates (camera bearings), and **x** for predicted world coordinates\n",
    "\n",
    "However, we don't know **x**, we only get a dsitribution over x from some upstream system of the pipeline. So **x** is modeled with a GMM:\n",
    "\n",
    "$p(x)=\\sum^{K}_{k=1}\\pi_k N(\\mu_k, \\sigma_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-savage",
   "metadata": {},
   "source": [
    "For simplicity we assume that all **x** have K=3. And each datapoint will have $K*\\{\\pi,\\mu,\\sigma\\}$ parameters, so 9 per datapoint. Therefore the dataset will be:\n",
    "* **y.shape = (dataset_size,)** - associated camera coordinate (which we know)\n",
    "* **x.shape = (dataset_size, 9)**\n",
    "\n",
    "The image which generated the data was ambigious and there are two modes which generated the data (i.e. if our upstream input was an image, then there would be two meanigful poses that we should be able to predict). \n",
    "\n",
    "Therefore there will some datappoints with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=13)  # set seed so the dataset is the same whenever this NB is ran\n",
    "\n",
    "dataset_size = 3000\n",
    "num_modes = 3\n",
    "noise = 0.005\n",
    "\n",
    "x = np.random.uniform(-1,1, dataset_size)\n",
    "x_mode = np.random.choice(num_modes, dataset_size)\n",
    "\n",
    "a = np.random.uniform(-1,1,num_modes)\n",
    "b = np.random.uniform(-0,0,num_modes)\n",
    "\n",
    "y = np.empty(x.shape)\n",
    "# get modes\n",
    "for i in range(num_modes):\n",
    "    y[x_mode == i] = x[x_mode == i] * a[i] + b[i] + np.random.normal(scale=noise, size=x[x_mode == i].shape)\n",
    "    \n",
    "\n",
    "# add some outlier points\n",
    "y_tmp = np.random.uniform(y.min(), y.max(), size=int(0.1 * dataset_size))\n",
    "x_tmp = np.random.uniform(-1,1, int(0.1 * dataset_size))\n",
    "x_mode_tmp = np.ones(300) * num_modes\n",
    "\n",
    "x = np.concatenate((x, x_tmp))\n",
    "y = np.concatenate((y, y_tmp))\n",
    "x_mode = np.concatenate((x_mode, x_mode_tmp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 loc",
   "language": "python",
   "name": "localication"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

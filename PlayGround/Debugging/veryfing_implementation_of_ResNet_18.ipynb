{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lucky-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-sensitivity",
   "metadata": {},
   "source": [
    "# ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlled-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import add\n",
    "\n",
    "\n",
    "\n",
    "def conv_bn_relu(**conv_params):\n",
    "    \" builds: conv -> BN -> relu block \"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = layers.Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                        strides=strides, padding=padding,\n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        kernel_regularizer=kernel_regularizer)(input)\n",
    "\n",
    "        norm = layers.BatchNormalization(axis=-1)(conv)\n",
    "        act = layers.Activation(\"relu\")(norm)\n",
    "        return act\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bn_relu_conv(**conv_params):\n",
    "    \"\"\"\n",
    "    same as - conv_bn_relu - but with changed order\n",
    "    builds: BN -> relu block ->  conv \n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    # kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        norm = layers.BatchNormalization(axis=-1)(input)\n",
    "        act = layers.Activation(\"relu\")(norm)\n",
    "        conv = layers.Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                        strides=strides, padding=padding,\n",
    "                        kernel_initializer=kernel_initializer, #kernel_regularizer=kernel_regularizer\n",
    "                        )(act)\n",
    "        return conv\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1)):\n",
    "\n",
    "    def f(input):\n",
    "        conv = bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                strides=init_strides)(input)\n",
    "\n",
    "        residual = bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv)\n",
    "        \n",
    "        shortcut = input\n",
    "        if init_strides == (2,2):\n",
    "            shortcut = layers.Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                          strides=init_strides,\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\")(shortcut)\n",
    "        output = add([shortcut, residual])\n",
    "        return output\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "def basic_block_first(filters, init_strides=(1, 1)):\n",
    "\n",
    "    def f(input):\n",
    "        conv = layers.Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                        strides=init_strides,\n",
    "                        padding=\"same\",\n",
    "                        kernel_initializer=\"he_normal\")(input)\n",
    "\n",
    "        residual = bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv)\n",
    "        \n",
    "        shortcut = input\n",
    "        if init_strides == (2,2):\n",
    "            shortcut = layers.Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                          strides=init_strides,\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\")(shortcut)\n",
    "        output = add([shortcut, residual])\n",
    "        return output\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intended-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def resNet_18_encoder(input_shape=(224, 224, 3)):\n",
    "\n",
    "    image_input = layers.Input(shape=(224, 224, 3))\n",
    "\n",
    "    x = conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(image_input)  # output: 112x112\n",
    "    f0 = x\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)  # output: 56x56\n",
    "\n",
    "    # BLOCK 1 - 64 filters\n",
    "    x = basic_block_first(64, init_strides=(1, 1))(x) # output: 56x56\n",
    "    x = basic_block(64, init_strides=(1, 1))(x)\n",
    "    f1 = x\n",
    "\n",
    "    # BLOCK 2 - 128 filters\n",
    "    x = basic_block(128, init_strides=(2, 2))(x)  # output: 28x28\n",
    "    x = basic_block(128, init_strides=(1, 1))(x)\n",
    "    f2 = x\n",
    "\n",
    "    # BLOCK 3 - 256 filters\n",
    "    x = basic_block(256, init_strides=(2, 2))(x)  # output: 14x14\n",
    "    x = basic_block(256, init_strides=(1, 1))(x)\n",
    "    f3 = x\n",
    "\n",
    "    # BLOCK 4 - 512 filters\n",
    "    x = basic_block(512, init_strides=(2, 2))(x) # output: 7x7\n",
    "    x = basic_block(512, init_strides=(1, 1))(x)\n",
    "    f4 = x \n",
    "\n",
    "\n",
    "    return image_input, [f0, f1,f2,f3,f4]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-venture",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "twenty-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def vgg_encoder(input_shape=(224, 224, 3)):\n",
    "    \n",
    "    image_input = layers.Input(shape=(224, 224, 3))\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(image_input)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "    f1 = x\n",
    "    \n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    f2 = x\n",
    "    \n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    f5 = x\n",
    "    \n",
    "    return image_input, [f1,f2,f3,f4,f5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-spotlight",
   "metadata": {},
   "source": [
    "# FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "viral-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def resnet_fpn(num_regions, input_height=224, input_width=224):\n",
    "\n",
    "    model = fpn(resNet_18_encoder, num_regions, input_height=input_height, input_width=input_width)\n",
    "    model.model_name = \"resnet_fpn\"\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def fpn(encoder, num_regions, l1_skip_conn=True, input_height=224,\n",
    "          input_width=224):\n",
    "\n",
    "    image_input = layers.Input(shape=(224, 224, 3))\n",
    "    mask = layers.Input(shape=(224, 224, 3))\n",
    "    \n",
    "    image_input, levels = encoder(image_input)\n",
    "    [f0, f1,f2,f3,f4] = levels\n",
    "    # paper says: f0 should be disregarded due to high memory footprint.\n",
    "\n",
    "    # ***** FPN *****\n",
    "    # 7x7 to 14x14\n",
    "    P4 = f4\n",
    "    f4_prime = layers.Conv2D(256, (1,1))(P4)\n",
    "    x = layers.UpSampling2D((2, 2))(f4_prime)\n",
    "    f3_prime = layers.Conv2D(256, (1,1))(f3)\n",
    "    x = layers.Add()([x, f3_prime])\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization(axis=-1)(x)\n",
    "    P3 = layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "    # 14x14 to 28x28\n",
    "    x = layers.UpSampling2D((2, 2))(P3)\n",
    "    f2_prime = layers.Conv2D(256, (1,1))(f2)\n",
    "    x = layers.Add()([x, f2_prime])\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization(axis=-1)(x)\n",
    "    P2 = layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "    # 28x28 to 56x56\n",
    "    x = layers.UpSampling2D((2, 2))(P2)\n",
    "    f1_prime = layers.Conv2D(256, (1,1))(f1)\n",
    "    x = layers.Add()([x, f1_prime])\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization(axis=-1)(x)\n",
    "    P1 = layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "\n",
    "    # ***** UPSAMPLE *****\n",
    "    # upsample to 1/4 org. image\n",
    "    # P4 - 1\n",
    "    up_p4 = layers.Conv2D(128, (3, 3), padding='same')(P4)\n",
    "    up_p4 = layers.BatchNormalization(axis=-1)(up_p4)  # tfa.layers.GroupNormalization()\n",
    "    up_p4 = layers.Activation(\"relu\")(up_p4)\n",
    "    up_p4 = layers.UpSampling2D((2, 2))(up_p4)\n",
    "\n",
    "    # P4 - 2\n",
    "    up_p4 = layers.Conv2D(128, (3, 3), padding='same')(up_p4)\n",
    "    up_p4 = layers.BatchNormalization(axis=-1)(up_p4)  # tfa.layers.GroupNormalization()\n",
    "    up_p4 = layers.Activation(\"relu\")(up_p4)\n",
    "    up_p4 = layers.UpSampling2D((2, 2))(up_p4)\n",
    "\n",
    "    # P4 - 1\n",
    "    up_p4 = layers.Conv2D(128, (3, 3), padding='same')(up_p4)\n",
    "    up_p4 = layers.BatchNormalization(axis=-1)(up_p4)  # tfa.layers.GroupNormalization()\n",
    "    up_p4 = layers.Activation(\"relu\")(up_p4)\n",
    "    up_p4 = layers.UpSampling2D((2, 2))(up_p4)\n",
    "\n",
    "\n",
    "\n",
    "    # P3 - 1\n",
    "    up_p3 = layers.Conv2D(128, (3, 3), padding='same')(P3)\n",
    "    up_p3 = layers.BatchNormalization(axis=-1)(up_p3)  # tfa.layers.GroupNormalization()\n",
    "    up_p3 = layers.Activation(\"relu\")(up_p3)\n",
    "    up_p3 = layers.UpSampling2D((2, 2))(up_p3)\n",
    "\n",
    "    # P3 - 2\n",
    "    up_p3 = layers.Conv2D(128, (3, 3), padding='same')(up_p3)\n",
    "    up_p3 = layers.BatchNormalization(axis=-1)(up_p3)  # tfa.layers.GroupNormalization()\n",
    "    up_p3 = layers.Activation(\"relu\")(up_p3)\n",
    "    up_p3 = layers.UpSampling2D((2, 2))(up_p3)\n",
    "\n",
    "\n",
    "\n",
    "    # P2 - 1\n",
    "    up_p2 = layers.Conv2D(128, (3, 3), padding='same')(P2)\n",
    "    up_p2 = layers.BatchNormalization(axis=-1)(up_p2)  # tfa.layers.GroupNormalization()\n",
    "    up_p2 = layers.Activation(\"relu\")(up_p2)\n",
    "    up_p2 = layers.UpSampling2D((2, 2))(up_p2)\n",
    "\n",
    "    # P2\n",
    "    up_p1 = layers.Conv2D(128, (3, 3), padding='same')(P1)\n",
    "    up_p1 = layers.BatchNormalization(axis=-1)(up_p1)  # tfa.layers.GroupNormalization()\n",
    "    up_p1 = layers.Activation(\"relu\")(up_p1)\n",
    "\n",
    "\n",
    "    # SUM ELEMENT WISE\n",
    "    y = layers.Add()([up_p4, up_p3, up_p2, up_p1])\n",
    "    y = layers.UpSampling2D((4, 4))(y)\n",
    "\n",
    "\n",
    "    # REGRESSION\n",
    "    output_reg = layers.Conv2D(3, (3, 3), padding='same')(y)\n",
    "    output_masked_reg = layers.Multiply()([output_reg, mask])\n",
    "\n",
    "    \n",
    "    # CLASSIFICATION\n",
    "    x_clas = layers.Conv2D(num_regions, (3, 3), padding='same')(y)\n",
    "    output_clas = keras.activations.softmax(x_clas, axis=-1)\n",
    "    \n",
    "    \n",
    "    # CONCATENATE\n",
    "    output = layers.Concatenate(axis=-1)([output_masked_reg, output_clas])\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[image_input, mask], outputs=output) \n",
    "#     model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-favorite",
   "metadata": {},
   "source": [
    "# UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "continued-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def resnet_unet(num_regions, input_height=224, input_width=224):\n",
    "\n",
    "    model = unet(resNet_18_encoder, num_regions, input_height=input_height, input_width=input_width)\n",
    "    model.model_name = \"vgg_unet\"\n",
    "    \n",
    "    return model\n",
    "\n",
    "def vgg_unet(num_regions, input_height=224, input_width=224):\n",
    "\n",
    "    model = unet(vgg_encoder, num_regions, input_height=input_height, input_width=input_width)\n",
    "    model.model_name = \"vgg_unet\"\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def unet(encoder, num_regions, l1_skip_conn=True, input_height=224,\n",
    "          input_width=224):\n",
    "\n",
    "    image_input = layers.Input(shape=(224, 224, 3))\n",
    "    mask = layers.Input(shape=(224, 224, 3))\n",
    "    \n",
    "    image_input, levels = encoder(image_input)\n",
    "    [f1, f2, f3, f4, f5] = levels\n",
    "\n",
    "    o = f4\n",
    "    o = (layers.ZeroPadding2D((1, 1), name='U_block1_zero_pad'))(o)\n",
    "    o = (layers.Conv2D(512, (3, 3), padding='valid' , activation='relu', name='U_block1_conv'))(o)\n",
    "    o = (layers.BatchNormalization(name='U_block1_batch_norm'))(o)\n",
    "\n",
    "    o = (layers.UpSampling2D((2, 2), name='U_block2_up_sample'))(o)\n",
    "    o = (layers.concatenate([o, f3], axis=-1, name='U_block2_concat'))\n",
    "    o = (layers.ZeroPadding2D((1, 1)))(o)\n",
    "    o = (layers.Conv2D(512, (3, 3), padding='valid', activation='relu'))(o)\n",
    "    o = (layers.BatchNormalization())(o)\n",
    "\n",
    "    o = (layers.UpSampling2D((2, 2)))(o)\n",
    "    o = (layers.concatenate([o, f2], axis=-1))\n",
    "    o = (layers.ZeroPadding2D((1, 1)))(o)\n",
    "    o = (layers.Conv2D(256, (3, 3), padding='valid' , activation='relu'))(o)\n",
    "    o = (layers.BatchNormalization())(o)\n",
    "\n",
    "    o = (layers.UpSampling2D((2, 2)))(o)\n",
    "\n",
    "    if l1_skip_conn:\n",
    "        o = (layers.concatenate([o, f1], axis=-1))\n",
    "\n",
    "    o = (layers.ZeroPadding2D((1, 1)))(o)\n",
    "    o = (layers.Conv2D(128, (3, 3), padding='valid', activation='relu'))(o)\n",
    "    o = (layers.BatchNormalization())(o)\n",
    "\n",
    "    o = layers.Conv2D(128, (3, 3), padding='same')(o)\n",
    "    \n",
    "    o = (layers.UpSampling2D((2, 2)))(o)\n",
    "    o = (layers.ZeroPadding2D((1, 1)))(o)\n",
    "    o = (layers.Conv2D(64, (3, 3), padding='valid', activation='relu'))(o)\n",
    "    o = (layers.BatchNormalization())(o)\n",
    "    \n",
    "\n",
    "    # REGRESSION\n",
    "    output_reg = layers.Conv2D(3, (3, 3), padding='same')(o)\n",
    "    output_masked_reg = layers.Multiply()([output_reg, mask])\n",
    "\n",
    "    \n",
    "    # CLASSIFICATION\n",
    "    o_clas = layers.Conv2D(num_regions, (3, 3), padding='same')(o)\n",
    "    output_clas = keras.activations.softmax(o_clas, axis=-1)\n",
    "    \n",
    "    \n",
    "    # CONCATENATE\n",
    "    output = layers.Concatenate(axis=-1)([output_masked_reg, output_clas])\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[image_input, mask], outputs=output) \n",
    "#     model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-matthew",
   "metadata": {},
   "source": [
    "# Memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "victorian-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_profiler import model_profiler\n",
    "Batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-rebel",
   "metadata": {},
   "source": [
    "### FPN + ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eastern-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: VGG-16 backbone\n",
      "| Model Profile                    | Value               | Unit    |\n",
      "|----------------------------------|---------------------|---------|\n",
      "| Selected GPUs                    | ['0']               | GPU IDs |\n",
      "| No. of FLOPs                     | 0.28328173007999996 | BFLOPs  |\n",
      "| GPU Memory Requirement           | 7.297399893403053   | GB      |\n",
      "| Model Parameters                 | 15.292816           | Million |\n",
      "| Memory Required by Model Weights | 58.33746337890625   | MB      |\n"
     ]
    }
   ],
   "source": [
    "model = resnet_fpn(141, input_height=224, input_width=224)\n",
    "\n",
    "profile = model_profiler(model, Batch_size)\n",
    "\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-arrangement",
   "metadata": {},
   "source": [
    "### UNET + ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cardiac-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model Profile                    | Value               | Unit    |\n",
      "|----------------------------------|---------------------|---------|\n",
      "| Selected GPUs                    | ['0']               | GPU IDs |\n",
      "| No. of FLOPs                     | 0.44885446543999996 | BFLOPs  |\n",
      "| GPU Memory Requirement           | 10.60492904484272   | GB      |\n",
      "| Model Parameters                 | 8.923216            | Million |\n",
      "| Memory Required by Model Weights | 34.03936767578125   | MB      |\n"
     ]
    }
   ],
   "source": [
    "model = resnet_unet(141, input_height=224, input_width=224)\n",
    "\n",
    "profile = model_profiler(model, Batch_size)\n",
    "\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-shift",
   "metadata": {},
   "source": [
    "### UNET + VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "played-outdoors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model Profile                    | Value              | Unit    |\n",
      "|----------------------------------|--------------------|---------|\n",
      "| Selected GPUs                    | ['0']              | GPU IDs |\n",
      "| No. of FLOPs                     | 0.7231124718399999 | BFLOPs  |\n",
      "| GPU Memory Requirement           | 11.549675717949867 | GB      |\n",
      "| Model Parameters                 | 15.688464          | Million |\n",
      "| Memory Required by Model Weights | 59.84674072265625  | MB      |\n"
     ]
    }
   ],
   "source": [
    "model = vgg_unet(141, input_height=224, input_width=224)\n",
    "\n",
    "profile = model_profiler(model, Batch_size)\n",
    "\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-multimedia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "noble-confusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3660869565217391"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(11.5- 7.29) / 11.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-albania",
   "metadata": {},
   "source": [
    "# ResNet 18 - github implementation\n",
    "### implementation as presented in: https://github.com/raghakot/keras-resnet/blob/master/resnet.py\n",
    "### I wanted to implement ResNet 18 myself and use this for comparison i.e. to check whether i have connected everything properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "interpreted-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    ROW_AXIS = 1\n",
    "    COL_AXIS = 2\n",
    "    CHANNEL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        input_shape = (224,224,3)\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "#         Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=block)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "corresponding-sight",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ResnetBuilder.build_resnet_18((224,224,3), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "requested-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-symphony",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 loc",
   "language": "python",
   "name": "localication"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
